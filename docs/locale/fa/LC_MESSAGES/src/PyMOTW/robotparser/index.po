# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2016, Python-ir.org
# This file is distributed under the same license as the Python-ir package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2016.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Python-ir 0.1\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2016-05-07 20:31+0430\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.3.4\n"

#: ../../src/PyMOTW/robotparser/index.rst:3
msgid "robotparser -- Internet spider access control"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:8
msgid "Parse robots.txt file used to control Internet spiders"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:9
msgid "2.1.3 and later"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:11
msgid ""
":mod:`robotparser` implements a parser for the ``robots.txt`` file "
"format, including a simple function for checking if a given user agent "
"can access a resource.  It is intended for use in well-behaved spiders or"
" other crawler applications that need to either be throttled or otherwise"
" restricted."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:15
msgid ""
"The :mod:`robotparser` module has been renamed :mod:`urllib.robotparser` "
"in Python 3.0. Existing code using :mod:`robotparser` can be updated "
"using 2to3."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:19
msgid "robots.txt"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:21
msgid ""
"The ``robots.txt`` file format is a simple text-based access control "
"system for computer programs that automatically access web resources "
"(\"spiders\", \"crawlers\", etc.).  The file is made up of records that "
"specify the user agent identifier for the program followed by a list of "
"URLs (or URL prefixes) the agent may not access."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:23
msgid "This is the ``robots.txt`` file for ``http://www.doughellmann.com/``:"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:28
msgid ""
"It prevents access to some of the expensive parts of my site that would "
"overload the server if a search engine tried to index them.  For a more "
"complete set of examples, refer to `The Web Robots Page`_."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:31
msgid "Simple Example"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:33
msgid ""
"Using the data above, a simple crawler can test whether it is allowed to "
"download a page using the ``RobotFileParser``'s ``can_fetch()`` method."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:39
msgid ""
"The URL argument to ``can_fetch()`` can be a path relative to the root of"
" the site, or full URL."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:67
msgid "Long-lived Spiders"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:69
msgid ""
"An application that takes a long time to process the resources it "
"downloads or that is throttled to pause between downloads may want to "
"check for new ``robots.txt`` files periodically based on the age of the "
"content it has downloaded already.  The age is not managed automatically,"
" but there are convenience methods to make tracking it easier."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:75
msgid ""
"This extreme example downloads a new ``robots.txt`` file if the one it "
"has is more than 1 second old."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:100
msgid ""
"A \"nicer\" version of the long-lived application might request the "
"modification time for the file before downloading the entire thing.  On "
"the other hand, ``robots.txt`` files are usually fairly small, so it "
"isn't that much more expensive to just grab the entire document again."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:106
msgid "`robotparser <http://docs.python.org/library/robotparser.html>`_"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:106
msgid "The standard library documentation for this module."
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:108
msgid "`The Web Robots Page`_"
msgstr ""

#: ../../src/PyMOTW/robotparser/index.rst:109
msgid "Description of robots.txt format."
msgstr ""

